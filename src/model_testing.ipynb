{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "from nltk.metrics import precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wessel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "  Training set: 34108\n",
      "  Test set: 4264\n",
      "  Development set: 4264\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import sys\n",
    "from string import punctuation\n",
    "import pickle\n",
    "\n",
    "from nltk import download, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the nltk stopwords corpus if needed\n",
    "download('stopwords')\n",
    "\n",
    "\n",
    "def create_dataset(filepath):\n",
    "    ''' Reads and cleans the csv file and structures the datapoints ''' \n",
    "    dataset = []\n",
    "\n",
    "    # The translation and set are both a lot faster O(1) \n",
    "    # when compared to checking a list or string O(n).\n",
    "    punct_translation = str.maketrans('', '', punctuation)\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "\n",
    "    with open(filepath, 'r', encoding='latin-1') as f:\n",
    "        reader = csv.reader(f, delimiter=\",\", )\n",
    "        \n",
    "        # Skip the header row\n",
    "        next(reader, None)\n",
    "\n",
    "        # Items per row:\n",
    "        #   0 -> review id\n",
    "        #   1 -> rating between 1-5\n",
    "        #   2 -> year and month\n",
    "        #   3 -> location of reviewer\n",
    "        #   4 -> review text\n",
    "        #   5 -> Disneyland location\n",
    "        for row in reader:\n",
    "            rating = int(row[1])\n",
    "\n",
    "            if rating < 3:\n",
    "                rating_label = 'negative'\n",
    "            elif rating == 3:\n",
    "                rating_label = 'indifferent'\n",
    "            else:\n",
    "                rating_label = 'positive'\n",
    "\n",
    "            review_text = row[4] \\\n",
    "                .translate(punct_translation) \\\n",
    "                .lower() \\\n",
    "                .strip()\n",
    "\n",
    "            tokenized = [\n",
    "                token for token in word_tokenize(review_text)\n",
    "                if token not in stoplist\n",
    "            ]\n",
    "\n",
    "            bag_of_words = ({t: True for t in tokenized}, rating_label)\n",
    "\n",
    "            dataset.append(\n",
    "                (tokenized, bag_of_words, rating_label, row[2], row[3], row[5])\n",
    "            )\n",
    "\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def split_train_test(feats, split=0.8):\n",
    "    ''' Creates test, train and dev splits from the dataset ''' \n",
    "    random.Random(1).shuffle(feats)\n",
    "\n",
    "    cutoff = int(len(feats) * split)\n",
    "    tenpercent = int((len(feats) - cutoff) / 2)\n",
    "    split = cutoff + tenpercent\n",
    "\n",
    "    train_feats = feats[:cutoff]\n",
    "    test_feats = feats[cutoff:split]\n",
    "    dev_feats = feats[split:]\n",
    "\n",
    "    print(\"  Training set: %i\" % len(train_feats))\n",
    "    print(\"  Test set: %i\" % len(test_feats))\n",
    "    print(\"  Development set: %i\" % len(dev_feats))\n",
    "\n",
    "    return train_feats, test_feats, dev_feats\n",
    "\n",
    "train_feats, test_feats, dev_feats = split_train_test(\n",
    "    create_dataset('../data/DisneylandReviews.csv')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(classifier, testfeats):\n",
    "\trefsets = defaultdict(set)\n",
    "\ttestsets = defaultdict(set)\n",
    "\t\n",
    "\tfor i, (feats, label) in enumerate(testfeats):\n",
    "\t\trefsets[label].add(i)\n",
    "\t\tobserved = classifier.classify(feats)\n",
    "\t\ttestsets[observed].add(i)\n",
    "\t\n",
    "\tprecisions = {}\n",
    "\trecalls = {}\n",
    "\t\n",
    "\tfor label in classifier.labels():\n",
    "\t\tprecisions[label] = precision(refsets[label], testsets[label])\n",
    "\t\trecalls[label] = recall(refsets[label], testsets[label])\n",
    "\t\n",
    "\treturn precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f(precisions, recalls):\n",
    "    f_measures = {}\n",
    "\n",
    "    for category in precisions.keys():\n",
    "        # This is done to prevent the program from crashing when \n",
    "        # no measure is provided for a particular category\n",
    "        if not precisions[category] or not recalls[category]:\n",
    "            f_measures[category] = None\n",
    "            continue\n",
    "\n",
    "        f_measures[category] = round(\n",
    "            2 * ((precisions[category] * recalls[category]) /\n",
    "                 (precisions[category] + recalls[category])), 6)\n",
    "\n",
    "    return f_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(classifier, test_feats, categories):\n",
    "    \"\"\" Taken from assignment 1, calculates and prints evaluation measures \"\"\"\n",
    "    print(\"\\n##### Evaluation...\")\n",
    "    print(\"  Accuracy: %f\" % nltk.classify.accuracy(classifier, test_feats))\n",
    "    precisions, recalls = precision_recall(classifier, test_feats)\n",
    "    f_measures = calculate_f(precisions, recalls)\n",
    "\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")\n",
    "    print(\" |%-11s|%-11s|%-11s|%-11s|\" %\n",
    "          (\"category\", \"precision\", \"recall\", \"F-measure\"))\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")\n",
    "    for category in categories:\n",
    "        if precisions[category] is None:\n",
    "            print(\" |%-11s|%-11s|%-11s|%-11s|\" % (category, \"NA\", \"NA\", \"NA\"))\n",
    "        else:\n",
    "            print(\" |%-11s|%-11f|%-11f|%-11s|\" %\n",
    "                  (category,\n",
    "                   precisions[category],\n",
    "                   recalls[category],\n",
    "                   f_measures[category])\n",
    "                  )\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_feats):\n",
    "    ''' Trains and returns a linear SVM classifier '''\n",
    "    return SklearnClassifier(LinearSVC(dual=False)).train(train_feats)\n",
    "\n",
    "def train_knn(train_feats):\n",
    "    ''' Trains and returns a KNN classifier '''\n",
    "    return SklearnClassifier(KNeighborsClassifier()).train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_bow_test = [item[1] for item in test_feats]\n",
    "only_bow_train = [item[1] for item in train_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = train_svm(only_bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = train_knn(only_bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.809334\n",
      " |-----------|-----------|-----------|-----------|\n",
      " |category   |precision  |recall     |F-measure  |\n",
      " |-----------|-----------|-----------|-----------|\n",
      " |positive   |0.891508   |0.931178   |0.910911   |\n",
      " |indifferent|0.338747   |0.275992   |0.304167   |\n",
      " |negative   |0.532051   |0.456044   |0.491124   |\n",
      " |-----------|-----------|-----------|-----------|\n",
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.787523\n",
      " |-----------|-----------|-----------|-----------|\n",
      " |category   |precision  |recall     |F-measure  |\n",
      " |-----------|-----------|-----------|-----------|\n",
      " |positive   |0.795530   |0.992584   |0.883199   |\n",
      " |indifferent|0.088235   |0.005671   |0.010657   |\n",
      " |negative   |0.375000   |0.024725   |0.046392   |\n",
      " |-----------|-----------|-----------|-----------|\n"
     ]
    }
   ],
   "source": [
    "evaluation(svm_classifier, only_bow_test, ['positive', 'indifferent', 'negative'])\n",
    "evaluation(knn_classifier, only_bow_test, ['positive', 'indifferent', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import spacy\n",
    "# spacy.load('en_core_web_md')\n",
    "# \n",
    "# TODO: word embeddings aan de dataset toevoegen\n",
    "# Denk dat bij het inlezen dit het beste is om te doen, dan hoeven we maar 1x door alles\n",
    "# heen te loopen. Even uitzoeken hoe de embedding vectors meegegeven moeten worden \n",
    "# (dict net als BOW of tuple met (<lijst met vectors>, <label>))"
   ]
  }
 ]
}