{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitmlpconda7f86b9b3c7f847e99c33aa47d858c0d9",
   "display_name": "Python 3.8.5 64-bit ('mlp': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "from nltk.metrics import precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nTODO: word embeddings aan de dataset toevoegen\\nDenk dat bij het inlezen dit het beste is om te doen, dan hoeven we maar 1x door alles\\nheen te loopen. Even uitzoeken hoe de embedding vectors meegegeven moeten worden \\n(dict net als BOW of tuple met (<lijst met vectors>, <label>))\\n\\nEven experimenteren met wat beter werkt: \\n    - soort bow van individuele token vectors per review\\n    - of een gecombineerde methode gebruiken \\n        -> gemiddelde van alle token vectors\\n        -> doc vector\\n        -> ???\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# We only need the sentence splitting and word embedding features, disabling the\n",
    "# unneed features makes this a lot faster.\n",
    "nlp = spacy.load('en_core_web_md', disable=['tagger', 'ner'])\n",
    "\n",
    "'''\n",
    "TODO: word embeddings aan de dataset toevoegen\n",
    "Denk dat bij het inlezen dit het beste is om te doen, dan hoeven we maar 1x door alles\n",
    "heen te loopen. Even uitzoeken hoe de embedding vectors meegegeven moeten worden \n",
    "(dict net als BOW of tuple met (<lijst met vectors>, <label>))\n",
    "\n",
    "Even experimenteren met wat beter werkt: \n",
    "    - soort bow van individuele token vectors per review\n",
    "    - of een gecombineerde methode gebruiken \n",
    "        -> gemiddelde van alle token vectors\n",
    "        -> doc vector\n",
    "        -> ???\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wessel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "  Training set: 34124\n",
      "  Test set: 4266\n",
      "  Development set: 4266\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import sys\n",
    "from string import punctuation\n",
    "import pickle\n",
    "\n",
    "from nltk import download, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the nltk stopwords corpus if needed\n",
    "download('stopwords')\n",
    "\n",
    "\n",
    "def create_dataset(filepath):\n",
    "    ''' Reads and cleans the csv file and structures the datapoints ''' \n",
    "    dataset = []\n",
    "\n",
    "    # The translation and set are both a lot faster O(1) \n",
    "    # when compared to checking a list or string O(n).\n",
    "    punct_translation = str.maketrans('', '', punctuation)\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "\n",
    "    with open(filepath, 'r', encoding='latin-1') as f:\n",
    "        reader = csv.reader(f, delimiter=\",\", )\n",
    "        \n",
    "        # Skip the header row\n",
    "        next(reader, None)\n",
    "\n",
    "        # Items per row:\n",
    "        #   0 -> review id\n",
    "        #   1 -> rating between 1-5\n",
    "        #   2 -> year and month\n",
    "        #   3 -> location of reviewer\n",
    "        #   4 -> review text\n",
    "        #   5 -> Disneyland location\n",
    "        for row in reader:\n",
    "            rating = int(row[1])\n",
    "\n",
    "            if rating < 3:\n",
    "                rating_label = 'negative'\n",
    "            elif rating == 3:\n",
    "                rating_label = 'indifferent'\n",
    "            else:\n",
    "                rating_label = 'positive'\n",
    "\n",
    "            review_text = row[4] \\\n",
    "                .translate(punct_translation) \\\n",
    "                .lower() \\\n",
    "                .strip()\n",
    "\n",
    "            tokenized = [\n",
    "                token for token in word_tokenize(review_text)\n",
    "                if token not in stoplist\n",
    "            ]\n",
    "\n",
    "            bag_of_words = ({t: True for t in tokenized}, rating_label)\n",
    "\n",
    "            dataset.append(\n",
    "                {\n",
    "                    'tokenized': tokenized, \n",
    "                    'bag_of_words': bag_of_words, \n",
    "                    'rating_label': rating_label, \n",
    "                    'year_month': row[2], \n",
    "                    'reviewer_location': row[3], \n",
    "                    'review_text': row[4], \n",
    "                    'disneyland_location': row[5],\n",
    "                    'doc_vector': nlp(' '.join(tokenized)).vector\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def split_train_test(feats, split=0.8):\n",
    "    ''' Creates test, train and dev splits from the dataset ''' \n",
    "    random.Random(1).shuffle(feats)\n",
    "\n",
    "    cutoff = int(len(feats) * split)\n",
    "    tenpercent = int((len(feats) - cutoff) / 2)\n",
    "    split = cutoff + tenpercent\n",
    "\n",
    "    train_feats = feats[:cutoff]\n",
    "    test_feats = feats[cutoff:split]\n",
    "    dev_feats = feats[split:]\n",
    "\n",
    "    print(\"  Training set: %i\" % len(train_feats))\n",
    "    print(\"  Test set: %i\" % len(test_feats))\n",
    "    print(\"  Development set: %i\" % len(dev_feats))\n",
    "\n",
    "    return train_feats, test_feats, dev_feats\n",
    "dataset = create_dataset('../data/DisneylandReviews.csv')\n",
    "\n",
    "train_feats, test_feats, dev_feats = split_train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(classifier, testfeats):\n",
    "\trefsets = defaultdict(set)\n",
    "\ttestsets = defaultdict(set)\n",
    "\t\n",
    "\tfor i, (feats, label) in enumerate(testfeats):\n",
    "\t\trefsets[label].add(i)\n",
    "\t\tobserved = classifier.classify(feats)\n",
    "\t\ttestsets[observed].add(i)\n",
    "\t\n",
    "\tprecisions = {}\n",
    "\trecalls = {}\n",
    "\t\n",
    "\tfor label in classifier.labels():\n",
    "\t\tprecisions[label] = precision(refsets[label], testsets[label])\n",
    "\t\trecalls[label] = recall(refsets[label], testsets[label])\n",
    "\t\n",
    "\treturn precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f(precisions, recalls):\n",
    "    f_measures = {}\n",
    "\n",
    "    for category in precisions.keys():\n",
    "        # This is done to prevent the program from crashing when \n",
    "        # no measure is provided for a particular category\n",
    "        if not precisions[category] or not recalls[category]:\n",
    "            f_measures[category] = None\n",
    "            continue\n",
    "\n",
    "        f_measures[category] = round(\n",
    "            2 * ((precisions[category] * recalls[category]) /\n",
    "                 (precisions[category] + recalls[category])), 6)\n",
    "\n",
    "    return f_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(classifier, test_feats, categories):\n",
    "    \"\"\" Taken from assignment 1, calculates and prints evaluation measures \"\"\"\n",
    "    print(\"\\n##### Evaluation...\")\n",
    "    print(\"  Accuracy: %f\" % nltk.classify.accuracy(classifier, test_feats))\n",
    "    precisions, recalls = precision_recall(classifier, test_feats)\n",
    "    f_measures = calculate_f(precisions, recalls)\n",
    "\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")\n",
    "    print(\" |%-11s|%-11s|%-11s|%-11s|\" %\n",
    "          (\"category\", \"precision\", \"recall\", \"F-measure\"))\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")\n",
    "    for category in categories:\n",
    "        if precisions[category] is None:\n",
    "            print(\" |%-11s|%-11s|%-11s|%-11s|\" % (category, \"NA\", \"NA\", \"NA\"))\n",
    "        else:\n",
    "            print(\" |%-11s|%-11f|%-11f|%-11s|\" %\n",
    "                  (category,\n",
    "                   precisions[category],\n",
    "                   recalls[category],\n",
    "                   f_measures[category])\n",
    "                  )\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_feats):\n",
    "    ''' Trains and returns a linear SVM classifier '''\n",
    "    return SklearnClassifier(LinearSVC(dual=False)).train(train_feats)\n",
    "\n",
    "def train_knn(train_feats):\n",
    "    ''' Trains and returns a KNN classifier '''\n",
    "    return SklearnClassifier(KNeighborsClassifier()).train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_bow_test = [item['bag_of_words'] for item in test_feats]\n",
    "only_bow_train = [item['bag_of_words'] for item in train_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = train_svm(only_bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = train_knn(only_bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.812705\n",
      " |-----------|-----------|-----------|-----------|\n",
      " |category   |precision  |recall     |F-measure  |\n",
      " |-----------|-----------|-----------|-----------|\n",
      " |positive   |0.889932   |0.932638   |0.910784   |\n",
      " |indifferent|0.364425   |0.321224   |0.341463   |\n",
      " |negative   |0.588235   |0.438144   |0.502216   |\n",
      " |-----------|-----------|-----------|-----------|\n",
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.786451\n",
      " |-----------|-----------|-----------|-----------|\n",
      " |category   |precision  |recall     |F-measure  |\n",
      " |-----------|-----------|-----------|-----------|\n",
      " |positive   |0.791835   |0.994337   |0.881607   |\n",
      " |indifferent|0.263158   |0.019120   |0.035651   |\n",
      " |negative   |0.600000   |0.023196   |0.044665   |\n",
      " |-----------|-----------|-----------|-----------|\n"
     ]
    }
   ],
   "source": [
    "evaluation(svm_classifier, only_bow_test, ['positive', 'indifferent', 'negative'])\n",
    "evaluation(knn_classifier, only_bow_test, ['positive', 'indifferent', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_we_test = [(item['doc_vector'], item['rating_label']) for item in test_feats]\n",
    "only_we_train = [(item['doc_vector'], item['rating_label']) for item in train_feats]\n",
    "\n",
    "only_vec_train = [i[0] for i in only_we_train]\n",
    "only_label_train = [j[1] for j in only_we_train]\n",
    "\n",
    "only_vec_test = [i[0] for i in only_we_test]\n",
    "only_label_test = [j[1] for j in only_we_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = LinearSVC().fit(only_vec_train, only_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8211439287388654"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "svm_classifier.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "source": [
    "# Acc met onbewerkte, ruwe review text als doc vector (spacy schoont en splitst)\n",
    "- SVM: 0.8218471636193155\n",
    "- KNN: 0.7740271917487107\n",
    "\n",
    "# Acc met tokenized en geschoonde tokens als doc vector \n",
    "- SVM: 0.8211439287388654\n",
    "- KNN: 0.7805907172995781\n",
    "\n",
    "# TODO\n",
    "- Uitproberen met individuele token vectors en niet de 'platgeslagen' doc vector.\n",
    "- Andere items uit de dataset als features toevoegen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7805907172995781"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier().fit(only_vec_train, only_label_train)\n",
    "knn_classifier.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return a.dot(b)/np.sqrt(a.dot(a) * b.dot(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def sklearn_model_evaluation(model, x_test, y_test):\n",
    "    # y_pred = model.predict(x_test)\n",
    "    # precision = precision_score(y_test, y_pred, average='micro')\n",
    "    # recall = recall_score(y_test, y_pred, average='micro')\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "\n",
    "    print(\"\\n##### Evaluation...\")\n",
    "    print(f\"  Accuracy: {accuracy}\") \n",
    "    print(f\"Precision: {precision}\\nRecall: {recall}\\nF-score: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "LinearSVC() "
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-3dfacdaeb72a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msvm_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_we_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn_classifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0monly_we_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array_repr_implementation\u001b[0;34m(arr, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[1;32m   1384\u001b[0m         \u001b[0mlst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1386\u001b[0;31m         lst = array2string(arr, max_line_width, precision, suppress_small,\n\u001b[0m\u001b[1;32m   1387\u001b[0m                            ', ', prefix, suffix=suffix)\n\u001b[1;32m   1388\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# show zero-length shape unless it is (0,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m\"[]\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_array2string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m                 \u001b[0mrepr_running\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_array2string\u001b[0;34m(a, options, separator, prefix)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0mnext_line_prefix\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m     lst = _formatArray(a, format_function, options['linewidth'],\n\u001b[0m\u001b[1;32m    502\u001b[0m                        \u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'edgeitems'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                        summary_insert, options['legacy'])\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m_formatArray\u001b[0;34m(a, format_function, line_width, next_line_prefix, separator, edge_items, summary_insert, legacy)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0;31m# invoke the recursive part with an initial index and prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         return recurser(index=(),\n\u001b[0m\u001b[1;32m    819\u001b[0m                         \u001b[0mhanging_indent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnext_line_prefix\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m                         curr_width=line_width)\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mrecurser\u001b[0;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[1;32m    772\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    773\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrailing_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 774\u001b[0;31m                 \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrecurser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_hanging_indent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_width\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    775\u001b[0m                 s, line = _extendLine(\n\u001b[1;32m    776\u001b[0m                     s, line, word, elem_width, hanging_indent, legacy)\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36mrecurser\u001b[0;34m(index, hanging_indent, curr_width)\u001b[0m\n\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxes_left\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mformat_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;31m# when recursing, add a space to align with the [ added, and reduce the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/numpy/core/arrayprint.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0merrstate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(prec svm_classifier, only_we_train)\n",
    "print(prec knn_classifier, only_we_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.8211439287388654\n",
      "Precision: 0.8211439287388654\n",
      "Recall: 0.8211439287388654\n",
      "F-score: \n",
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.7805907172995781\n",
      "Precision: 0.7805907172995781\n",
      "Recall: 0.7805907172995781\n",
      "F-score: \n"
     ]
    }
   ],
   "source": [
    "sklearn_model_evaluation(svm_classifier, only_vec_test, only_label_test)\n",
    "sklearn_model_evaluation(knn_classifier, only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuel token vectors als feature toevoegen\n",
    "extra punten uit dataset toevoegen, kijken of daar regression of correlation mee gedaan kan worden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2019-5'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "sorted([item['year_month'] for item in dataset if item['year_month'] != 'missing'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}