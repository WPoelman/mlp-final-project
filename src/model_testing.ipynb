{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitmlpconda7f86b9b3c7f847e99c33aa47d858c0d9",
   "display_name": "Python 3.8.5 64-bit ('mlp': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "5bf958a91edb3543ce091915f3ee5476db47644f69ccdb37f88fb161a79b6684"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "from nltk.metrics import precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nTODO: word embeddings aan de dataset toevoegen\\nDenk dat bij het inlezen dit het beste is om te doen, dan hoeven we maar 1x door alles\\nheen te loopen. Even uitzoeken hoe de embedding vectors meegegeven moeten worden \\n(dict net als BOW of tuple met (<lijst met vectors>, <label>))\\n\\nEven experimenteren met wat beter werkt: \\n    - soort bow van individuele token vectors per review\\n    - of een gecombineerde methode gebruiken \\n        -> gemiddelde van alle token vectors\\n        -> doc vector\\n        -> ???\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# We only need the sentence splitting and word embedding features, disabling the\n",
    "# unneed features makes this a lot faster.\n",
    "nlp = spacy.load('en_core_web_md', disable=['tagger', 'ner'])\n",
    "\n",
    "'''\n",
    "TODO: word embeddings aan de dataset toevoegen\n",
    "Denk dat bij het inlezen dit het beste is om te doen, dan hoeven we maar 1x door alles\n",
    "heen te loopen. Even uitzoeken hoe de embedding vectors meegegeven moeten worden \n",
    "(dict net als BOW of tuple met (<lijst met vectors>, <label>))\n",
    "\n",
    "Even experimenteren met wat beter werkt: \n",
    "    - soort bow van individuele token vectors per review\n",
    "    - of een gecombineerde methode gebruiken \n",
    "        -> gemiddelde van alle token vectors\n",
    "        -> doc vector\n",
    "        -> ???\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([-2.5118e-01, -6.0606e-02, -3.4313e-01,  3.7411e-02, -8.4498e-02,\n",
       "        1.2884e-02,  2.4850e-01, -1.9731e-02,  2.4863e-01,  1.0369e+00,\n",
       "       -2.2219e-01,  4.5068e-01,  1.8731e-02,  3.5804e-01,  2.8142e-01,\n",
       "        1.0846e-01, -2.8425e-01,  1.4556e+00,  1.3171e-01,  1.2139e-01,\n",
       "       -3.7228e-01,  1.6142e-01, -7.8251e-02, -3.4224e-02,  2.8212e-01,\n",
       "       -3.0390e-01, -7.7036e-02, -6.9127e-02,  2.8540e-01,  2.1351e-01,\n",
       "       -9.2228e-03,  1.2881e-01,  1.9785e-01,  3.0749e-01, -1.4267e-02,\n",
       "        1.8628e-01,  7.1090e-03,  2.7434e-01,  1.1826e-01,  2.5580e-02,\n",
       "       -1.7196e-01,  9.0421e-02, -3.5220e-01,  3.8906e-01, -2.4534e-01,\n",
       "        8.6821e-02,  2.1425e-01, -2.3036e-02,  9.6637e-02,  1.3713e-01,\n",
       "        2.2984e-01,  9.2558e-03,  2.1766e-01, -3.5353e-01, -8.6038e-02,\n",
       "       -3.1343e-01, -2.0462e-01, -4.3504e-01, -1.6242e-01,  1.3472e-01,\n",
       "       -8.2011e-02,  2.6381e-02,  4.2198e-01, -2.8300e-01,  2.1186e-01,\n",
       "       -3.4468e-01,  1.7031e-01, -9.3016e-02, -1.1092e-01, -2.4558e-01,\n",
       "       -1.5045e-01,  2.7729e-01,  3.6568e-01, -2.0442e-01,  4.4436e-01,\n",
       "        9.3075e-02,  1.0726e-01,  1.8154e-04,  1.2995e-01,  7.4154e-02,\n",
       "        6.6220e-03, -3.6597e-02, -1.4661e-02,  1.4578e-01, -1.6647e-01,\n",
       "       -5.5614e-02,  6.6183e-01, -8.3439e-02,  2.7915e-01, -3.3313e-01,\n",
       "       -1.8907e-02, -1.9534e-01,  1.6282e-01,  1.1505e-01,  1.7722e-01,\n",
       "       -2.3067e-01,  3.8281e-01,  2.5703e-01,  2.2537e-01,  1.9768e-01,\n",
       "       -4.6799e-02, -1.8096e-03,  1.7511e-01, -8.9772e-02,  2.6741e-01,\n",
       "       -1.4812e+00, -3.4650e-01,  1.5584e-03, -1.4669e-01,  2.2111e-01,\n",
       "       -1.7422e-01, -6.4725e-01, -1.9901e-01,  2.0120e-01, -1.1154e-01,\n",
       "       -1.6286e-02, -9.7136e-02, -5.7758e-02, -1.3888e-01,  2.5425e-01,\n",
       "       -1.4806e-01, -5.7109e-02,  8.9990e-02,  6.6444e-02, -3.3313e-02,\n",
       "       -3.2120e-02,  3.0630e-01, -2.4804e-01,  4.8072e-02, -1.7361e-01,\n",
       "        7.0361e-02,  3.9254e-01, -1.5597e-01,  2.0779e-02,  1.8921e-01,\n",
       "       -4.3227e-02,  2.3169e-01, -2.6531e-02, -1.8772e-01, -8.5388e-02,\n",
       "       -1.0061e+00, -2.2638e-01,  2.0569e-01, -4.3317e-02,  3.8701e-01,\n",
       "       -9.2514e-02,  2.5371e-01,  3.6008e-01, -3.9411e-01,  6.9015e-02,\n",
       "        8.1663e-02, -3.2928e-02,  7.2512e-03,  5.8449e-02,  2.3849e-01,\n",
       "       -2.3421e-01, -4.4645e-01, -1.1316e-01,  3.9083e-01, -7.8867e-02,\n",
       "       -4.0552e-02,  4.8799e-02,  1.0760e-02,  1.5391e-01, -4.2118e-01,\n",
       "       -3.4868e-02, -4.0299e-01, -1.0641e-01, -1.4540e-01,  2.8316e-02,\n",
       "       -1.4041e-01,  4.0132e-02, -4.0699e-01, -1.3522e-01,  2.4474e-01,\n",
       "        4.2616e-01, -5.5708e-05,  2.2427e-01,  3.3981e-01, -2.3495e-01,\n",
       "        1.6453e-01, -1.6499e-01, -3.1593e-01, -4.0820e-03, -2.2296e-01,\n",
       "       -3.0630e-03, -1.1730e-01, -1.0771e-01,  3.3320e-01, -3.7125e-01,\n",
       "        3.0978e-01, -1.3020e-01, -9.6400e-02, -1.7785e-02,  3.0181e-01,\n",
       "       -1.9358e-01,  7.0269e-02, -9.8229e-02, -8.7421e-02,  1.9460e-01,\n",
       "        5.1050e-02, -1.5732e-01,  4.1953e-02,  9.9384e-02, -3.8345e-02,\n",
       "       -8.7916e-02,  3.6319e-03, -3.5324e-03,  3.5258e-01, -7.8830e-02,\n",
       "        3.5598e-01, -2.0660e-01,  4.6500e-01,  2.8798e-01,  5.4739e-02,\n",
       "       -2.7148e-01, -5.3891e-02, -2.0469e-01, -6.8278e-01,  6.8288e-02,\n",
       "        4.8408e-01,  2.2010e-01, -2.8957e-01, -1.1845e-01, -1.5646e-01,\n",
       "        1.1767e-01, -6.0591e-02, -1.1741e-01,  1.9035e-01, -1.1261e-01,\n",
       "       -3.2116e-01, -2.9225e-01,  2.6022e-01, -2.4665e-01,  2.8114e-01,\n",
       "       -1.3550e-01,  3.8166e-01,  2.0105e-01,  2.2216e-02, -1.1258e-01,\n",
       "       -1.7673e-01,  4.7365e-01,  1.9191e-01,  1.0307e-01,  5.6432e-02,\n",
       "       -8.3323e-02,  2.5489e-01,  2.4424e-01,  5.7746e-02, -2.7944e-01,\n",
       "        4.1043e-01,  3.3137e-02, -7.9481e-02, -2.9008e-01, -8.1842e-03,\n",
       "        4.7626e-01, -1.4337e-01, -3.4919e-02, -6.7914e-02, -1.4212e-01,\n",
       "       -2.2655e-02,  3.4300e-02,  2.4862e-01,  6.2155e-03,  1.5540e-01,\n",
       "       -4.6727e-02, -1.6788e-01,  1.3192e-01,  5.7850e-01,  7.3135e-02,\n",
       "       -1.4831e-01, -1.5398e-01,  2.3292e-01,  1.9376e-01, -3.3161e-01,\n",
       "       -3.6248e-02, -1.8094e-02, -1.5330e-01, -1.5187e-01,  2.2770e-01,\n",
       "        2.7996e-01, -1.9653e-01,  2.4781e-01,  7.5391e-02,  3.7055e-01,\n",
       "       -2.7225e-01, -8.7958e-02, -1.0262e-01,  1.4687e-01, -1.7648e-04,\n",
       "        1.4469e-01,  2.5192e-02, -3.2840e-01, -1.4958e-01,  9.2764e-02,\n",
       "        8.5058e-02,  9.5179e-03, -3.1619e-01,  2.3466e-01, -6.4746e-02],\n",
       "      dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "nlp('i.e').vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wessel/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-d9fd3c6ce73c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../data/DisneylandReviews.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0mtrain_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_feats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_feats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-d9fd3c6ce73c>\u001b[0m in \u001b[0;36mcreate_dataset\u001b[0;34m(filepath)\u001b[0m\n\u001b[1;32m     65\u001b[0m                     \u001b[0;34m'review_text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                     \u001b[0;34m'disneyland_location'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                     \u001b[0;34m'doc_vector'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m                 }\n\u001b[1;32m     69\u001b[0m             )\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, disable, component_cfg)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 \u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE088\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             )\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcomponent_cfg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m             \u001b[0mcomponent_cfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mmake_doc\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_format_docs_and_golds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import sys\n",
    "from string import punctuation\n",
    "import pickle\n",
    "\n",
    "from nltk import download, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the nltk stopwords corpus if needed\n",
    "download('stopwords')\n",
    "\n",
    "\n",
    "def create_dataset(filepath):\n",
    "    ''' Reads and cleans the csv file and structures the datapoints ''' \n",
    "    dataset = []\n",
    "\n",
    "    # The translation and set are both a lot faster O(1) \n",
    "    # when compared to checking a list or string O(n).\n",
    "    punct_translation = str.maketrans('', '', punctuation)\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "\n",
    "    with open(filepath, 'r', encoding='latin-1') as f:\n",
    "        reader = csv.reader(f, delimiter=\",\", )\n",
    "        \n",
    "        # Skip the header row\n",
    "        next(reader, None)\n",
    "\n",
    "        # Items per row:\n",
    "        #   0 -> review id\n",
    "        #   1 -> rating between 1-5\n",
    "        #   2 -> year and month\n",
    "        #   3 -> location of reviewer\n",
    "        #   4 -> review text\n",
    "        #   5 -> Disneyland location\n",
    "        for row in reader:\n",
    "            rating = int(row[1])\n",
    "\n",
    "            if rating < 3:\n",
    "                rating_label = 'negative'\n",
    "            elif rating == 3:\n",
    "                rating_label = 'indifferent'\n",
    "            else:\n",
    "                rating_label = 'positive'\n",
    "\n",
    "            review_text = row[4] \\\n",
    "                .translate(punct_translation) \\\n",
    "                .lower() \\\n",
    "                .strip() + f\"{row[5].replace('Disneyland_', '')} {row[3]}\"\n",
    "\n",
    "            tokenized = [\n",
    "                token for token in word_tokenize(review_text)\n",
    "                if token not in stoplist\n",
    "            ]\n",
    "\n",
    "            bag_of_words = ({t: True for t in tokenized}, rating)\n",
    "\n",
    "            dataset.append(\n",
    "                {\n",
    "                    'tokenized': tokenized, \n",
    "                    'bag_of_words': bag_of_words, \n",
    "                    'rating_label': rating, \n",
    "                    'year_month': row[2], \n",
    "                    'reviewer_location': row[3], \n",
    "                    'review_text': row[4], \n",
    "                    'disneyland_location': row[5],\n",
    "                    'doc_vector': nlp(' '.join(tokenized)).vector\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def split_train_test(feats, split=0.8):\n",
    "    ''' Creates test, train and dev splits from the dataset ''' \n",
    "    random.Random(1).shuffle(feats)\n",
    "\n",
    "    cutoff = int(len(feats) * split)\n",
    "    tenpercent = int((len(feats) - cutoff) / 2)\n",
    "    split = cutoff + tenpercent\n",
    "\n",
    "    train_feats = feats[:cutoff]\n",
    "    test_feats = feats[cutoff:split]\n",
    "    dev_feats = feats[split:]\n",
    "\n",
    "    print(\"  Training set: %i\" % len(train_feats))\n",
    "    print(\"  Test set: %i\" % len(test_feats))\n",
    "    print(\"  Development set: %i\" % len(dev_feats))\n",
    "\n",
    "    return train_feats, test_feats, dev_feats\n",
    "dataset = create_dataset('../data/DisneylandReviews.csv')\n",
    "\n",
    "train_feats, test_feats, dev_feats = split_train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(classifier, testfeats):\n",
    "\trefsets = defaultdict(set)\n",
    "\ttestsets = defaultdict(set)\n",
    "\t\n",
    "\tfor i, (feats, label) in enumerate(testfeats):\n",
    "\t\trefsets[label].add(i)\n",
    "\t\tobserved = classifier.classify(feats)\n",
    "\t\ttestsets[observed].add(i)\n",
    "\t\n",
    "\tprecisions = {}\n",
    "\trecalls = {}\n",
    "\t\n",
    "\tfor label in classifier.labels():\n",
    "\t\tprecisions[label] = precision(refsets[label], testsets[label])\n",
    "\t\trecalls[label] = recall(refsets[label], testsets[label])\n",
    "\t\n",
    "\treturn precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f(precisions, recalls):\n",
    "    f_measures = {}\n",
    "\n",
    "    for category in precisions.keys():\n",
    "        # This is done to prevent the program from crashing when \n",
    "        # no measure is provided for a particular category\n",
    "        if not precisions[category] or not recalls[category]:\n",
    "            f_measures[category] = None\n",
    "            continue\n",
    "\n",
    "        f_measures[category] = round(\n",
    "            2 * ((precisions[category] * recalls[category]) /\n",
    "                 (precisions[category] + recalls[category])), 6)\n",
    "\n",
    "    return f_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(classifier, test_feats, categories):\n",
    "    \"\"\" Taken from assignment 1, calculates and prints evaluation measures \"\"\"\n",
    "    print(\"\\n##### Evaluation...\")\n",
    "    print(\"  Accuracy: %f\" % nltk.classify.accuracy(classifier, test_feats))\n",
    "    precisions, recalls = precision_recall(classifier, test_feats)\n",
    "    f_measures = calculate_f(precisions, recalls)\n",
    "\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")\n",
    "    print(\" |%-11s|%-11s|%-11s|%-11s|\" %\n",
    "          (\"category\", \"precision\", \"recall\", \"F-measure\"))\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")\n",
    "    for category in categories:\n",
    "        if precisions[category] is None:\n",
    "            print(\" |%-11s|%-11s|%-11s|%-11s|\" % (category, \"NA\", \"NA\", \"NA\"))\n",
    "        else:\n",
    "            print(\" |%-11s|%-11f|%-11f|%-11s|\" %\n",
    "                  (category,\n",
    "                   precisions[category],\n",
    "                   recalls[category],\n",
    "                   f_measures[category])\n",
    "                  )\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_feats):\n",
    "    ''' Trains and returns a linear SVM classifier '''\n",
    "    return SklearnClassifier(LinearSVC(dual=False)).train(train_feats)\n",
    "\n",
    "def train_knn(train_feats):\n",
    "    ''' Trains and returns a KNN classifier '''\n",
    "    return SklearnClassifier(KNeighborsClassifier()).train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_bow_test = [item['bag_of_words'] for item in test_feats]\n",
    "only_bow_train = [item['bag_of_words'] for item in train_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = train_svm(only_bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = train_knn(only_bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(svm_classifier, only_bow_test, ['positive', 'indifferent', 'negative'])\n",
    "evaluation(knn_classifier, only_bow_test, ['positive', 'indifferent', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_we_test = [(item['doc_vector'], item['rating_label']) for item in test_feats]\n",
    "only_we_train = [(item['doc_vector'], item['rating_label']) for item in train_feats]\n",
    "\n",
    "only_vec_train = [i[0] for i in only_we_train]\n",
    "only_label_train = [j[1] for j in only_we_train]\n",
    "\n",
    "only_vec_test = [i[0] for i in only_we_test]\n",
    "only_label_test = [j[1] for j in only_we_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = LinearSVC().fit(only_vec_train, only_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5977496483825597"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "svm_classifier.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.43694327238631037"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "a = DecisionTreeClassifier().fit(only_vec_train, only_label_train)\n",
    "a.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries = {i['reviewer_location'] for i in dataset}\n",
    "disneylands = {i['disneyland_location'].replace('Disneyland_', '') for i in dataset}\n",
    "\n",
    "disneyland_lookup = { disneyland: nlp(disneyland).vector for disneyland in disneylands }\n",
    "country_lookup = { country: nlp(country).vector for country in countries }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_features_train = []\n",
    "labels_train = []\n",
    "\n",
    "for row in train_feats:\n",
    "    # We know these are always present in de dataset\n",
    "    features = row['doc_vector']\n",
    "\n",
    "    # if row['year_month'] == 'missing':\n",
    "    #     features = np.concatenate((features, np.array([0, 0])))\n",
    "    # else:\n",
    "    #     # example format: 2019-4\n",
    "    #     year, month = row['year_month'].split('-')\n",
    "    #     features = np.concatenate((features, np.array([int(year), int(month)])))\n",
    "    features = np.append(\n",
    "        features, \n",
    "        disneyland_lookup[row['disneyland_location'].replace('Disneyland_', '')]\n",
    "    )\n",
    "    features = np.append(features, country_lookup[row['reviewer_location']])\n",
    "\n",
    "    combined_features_train.append(features)\n",
    "    labels_train.append(row['rating_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_test = []\n",
    "labels_test = []\n",
    "for row in test_feats:\n",
    "    # We know these are always present in de dataset\n",
    "    features = row['doc_vector']\n",
    "    # features = np.array([])\n",
    "\n",
    "    # The feature arrays need to have the same shape, that is why we\n",
    "    # insert 0s in here\n",
    "    # if row['year_month'] == 'missing':\n",
    "    #     features = np.concatenate((features, np.array([0, 0])))\n",
    "    # else:\n",
    "    #     # example format: 2019-4\n",
    "    #     year, month = row['year_month'].split('-')\n",
    "    #     features = np.concatenate((features, np.array([int(year), int(month)])))\n",
    "\n",
    "    features = np.append(\n",
    "        features, \n",
    "        disneyland_lookup[row['disneyland_location'].replace('Disneyland_', '')]\n",
    "    )\n",
    "    features = np.append(features, country_lookup[row['reviewer_location']])\n",
    "\n",
    "    combined_features_test.append(features)\n",
    "    labels_test.append(row['rating_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/wessel/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5925925925925926"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "svm_extra_features = LinearSVC().fit(combined_features_train, labels_train)\n",
    "svm_extra_features.score(combined_features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'tokenized': ['convenience', 'staffs', 'friendly', 'many', 'rude', 'mainland', 'ppl', 'didnt', 'need', 'line', 'long', 'time', 'rides', 'several', 'restaurants', 'provide', 'nice', 'food'], 'bag_of_words': ({'convenience': True, 'staffs': True, 'friendly': True, 'many': True, 'rude': True, 'mainland': True, 'ppl': True, 'didnt': True, 'need': True, 'line': True, 'long': True, 'time': True, 'rides': True, 'several': True, 'restaurants': True, 'provide': True, 'nice': True, 'food': True}, 'positive'), 'rating_label': 'positive', 'year_month': '2016-12', 'reviewer_location': 'Hong Kong', 'review_text': 'Convenience, Staffs are friendly ,, there are not many rude mainland ppl,, didnt need to line up for long time for rides,   There are several restaurants provide nice food.', 'disneyland_location': 'Disneyland_HongKong', 'doc_vector': array([ 8.26215744e-03,  2.48817932e-02, -1.40969366e-01, -2.98998266e-01,\n        2.03529805e-01,  1.41831204e-01,  7.97833502e-02, -1.58968836e-01,\n        1.25683704e-02,  2.18018961e+00, -2.16656134e-01, -8.32059383e-02,\n        1.95899755e-02,  1.94423683e-02, -1.78535521e-01, -1.26981720e-01,\n       -1.10207908e-01,  1.11973250e+00, -9.99247432e-02, -3.02733183e-02,\n       -1.42959803e-01,  1.34889573e-01,  7.68425595e-03, -1.02654360e-01,\n        1.28734693e-01,  1.80763155e-02, -1.08306743e-01, -1.56741455e-01,\n        1.16818927e-01, -5.19425273e-02, -7.11692788e-04, -7.90104270e-02,\n       -4.57759462e-02, -1.17571615e-01,  7.39459842e-02, -1.11605301e-02,\n        1.11644618e-01,  2.37194747e-02, -1.27143428e-01,  8.67502689e-02,\n       -1.47649884e-01, -4.27900404e-02, -1.70620997e-02, -5.28801568e-02,\n        7.74667040e-02,  1.39552042e-01,  3.50495726e-02,  4.67126295e-02,\n        4.20314744e-02, -5.09617254e-02, -1.95529923e-01, -2.12064795e-02,\n        1.61097273e-01,  5.58712110e-02, -6.36019185e-02,  4.47471067e-02,\n       -1.69115886e-02, -8.06639120e-02,  3.38222571e-02,  2.08934434e-02,\n        1.23236403e-01, -2.02231228e-01, -1.25768214e-01,  1.37312874e-01,\n        8.54615271e-02, -2.08847281e-02,  3.87589037e-02,  2.58006334e-01,\n        1.29822806e-01,  2.21750513e-01,  1.43144011e-01,  1.67118847e-01,\n        1.10646628e-01,  2.23222133e-02,  2.22927123e-01,  7.74317756e-02,\n        1.01187147e-01,  5.18972985e-03,  4.05575102e-03,  2.11656138e-01,\n        1.86800584e-01, -4.38520014e-02, -1.01508453e-01, -6.84934780e-02,\n       -1.02343373e-01,  1.44823631e-02,  2.45318301e-02,  2.33556852e-01,\n        7.69519508e-02, -1.42846346e-01, -2.09094167e-01, -5.05993180e-02,\n       -1.17459372e-01, -1.89148914e-02,  1.69559941e-01, -1.19869001e-02,\n        1.83395259e-02, -1.43174320e-01,  7.66581595e-02,  6.63983822e-03,\n       -1.06211685e-01, -3.25126871e-02, -9.63822827e-02,  1.88524853e-02,\n        1.36511475e-01, -9.45913613e-01,  2.44002849e-01, -1.08653158e-01,\n       -6.75301179e-02, -6.89683408e-02,  7.55363107e-02, -3.42128724e-01,\n        6.40835240e-02,  1.37536481e-01,  2.00433675e-02, -1.29313022e-01,\n        2.32191049e-02, -1.55064002e-01, -2.13061452e-01,  3.28671038e-02,\n        1.17508195e-01, -8.98917299e-03,  1.72541887e-02, -1.52599826e-01,\n        2.73247901e-02, -1.49410546e-01,  1.31402537e-01, -2.38225237e-01,\n       -4.68078861e-03,  1.42135257e-02,  2.98700649e-02, -2.38751322e-02,\n       -5.06161265e-02, -4.65724654e-02, -4.12878171e-02, -1.95586830e-02,\n        4.66971099e-02, -6.24134801e-02,  6.30398393e-02, -1.86756831e-02,\n       -1.28571010e+00,  2.47872826e-02,  2.24331632e-01, -2.76853479e-02,\n        5.97955883e-02, -1.37148321e-01, -2.82873213e-01, -6.71143585e-04,\n       -1.87792983e-02, -5.55611476e-02, -1.46286879e-02,  2.05371469e-01,\n        8.92329067e-02, -1.34035572e-01,  4.37866263e-02,  8.92818347e-02,\n        1.07369974e-01, -2.79765874e-02,  1.39420822e-01, -9.13354754e-02,\n       -4.72346917e-02, -7.34069943e-03, -1.21790655e-02, -8.77090991e-02,\n        1.40749574e-01, -2.08558477e-02, -6.47054380e-03, -1.04228295e-01,\n       -1.70581753e-03, -1.03223100e-01,  6.07119985e-02,  5.28025515e-02,\n       -1.07215367e-01, -6.53244331e-02, -1.19085766e-01,  1.13791995e-01,\n       -8.38763565e-02,  1.22384369e-01, -2.39546667e-03,  7.26582035e-02,\n        1.22944884e-01, -1.41424879e-01, -2.38030136e-01,  5.91351166e-02,\n       -4.09522131e-02, -1.53558865e-01,  2.37387363e-02, -1.19746722e-01,\n        1.65081918e-01, -6.45724982e-02,  8.87298137e-02,  4.01342735e-02,\n       -9.30148140e-02, -5.30327000e-02, -7.56975859e-02,  1.21995257e-02,\n        7.08432272e-02, -5.22687696e-02,  7.64466822e-02,  1.17134586e-01,\n        1.10529521e-02, -1.03904745e-02, -5.53188063e-02, -8.94667506e-02,\n        2.74927139e-01,  1.49875492e-01,  4.05438952e-02,  2.07698494e-02,\n        8.82385373e-02,  8.23304243e-03, -3.34982164e-02, -4.69542146e-02,\n       -5.83561957e-02, -9.34786871e-02,  1.28664240e-01,  5.45747355e-02,\n        8.16462040e-02, -6.60035089e-02, -8.12363327e-02,  1.01004712e-01,\n        2.49574762e-02, -5.00166304e-02,  9.78486016e-02,  6.09328821e-02,\n        1.78782865e-02,  6.96507022e-02, -1.04041047e-01,  3.03445514e-02,\n       -1.05933130e-01, -5.01695508e-03, -5.36666922e-02, -8.13689977e-02,\n        1.48745164e-01,  4.60314751e-02,  2.68616915e-01, -3.50449933e-03,\n        5.57508841e-02, -1.43884435e-01, -1.05399072e-01,  2.15386540e-01,\n        4.91852826e-03,  2.24905722e-02, -7.25756660e-02,  1.63250282e-01,\n        7.31617585e-02,  3.05028912e-02, -2.82160401e-01, -1.18107520e-01,\n       -2.47485057e-01,  7.85601065e-02, -5.24530187e-03,  6.00137049e-03,\n       -1.29831269e-01,  6.88859448e-02, -2.72314792e-04,  3.57747644e-01,\n        2.37496849e-02, -9.12114084e-02, -1.87548921e-01,  5.75150624e-02,\n       -4.44940589e-02,  1.22924857e-01, -7.24252611e-02,  1.58846341e-02,\n       -7.37315193e-02, -3.13232020e-02,  4.48035225e-02,  1.62082538e-01,\n        1.90345585e-01,  1.23479001e-01, -2.36664146e-01,  2.65111085e-02,\n       -2.22311765e-02, -1.89289287e-01, -2.94562075e-02,  2.14343041e-01,\n        4.50727418e-02,  3.59030515e-02,  1.08802997e-01,  1.73218623e-01,\n       -8.44274182e-03,  1.37012839e-01,  4.14466821e-02,  2.59949118e-01,\n       -7.83860981e-02, -1.54447826e-02,  1.96974695e-01, -2.02616267e-02,\n        7.32047632e-02,  1.16019376e-01, -1.12544678e-01,  3.76474555e-03,\n       -8.93949419e-02, -6.03180490e-02,  9.86498520e-02,  4.26245853e-02,\n        1.07392915e-01, -1.16848066e-01,  1.54537842e-01,  2.17653751e-01],\n      dtype=float32)}\n[ 2 28]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U11')"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "ex = dev_feats[9]\n",
    "\n",
    "print(ex)\n",
    "\n",
    "f = np.array([disneyland_lookup[ex['disneyland_location']], country_lookup[ex['reviewer_location']]])\n",
    "\n",
    "print(f)\n",
    "\n",
    "svm_extra_features.predict(f.reshape(1,-1))"
   ]
  },
  {
   "source": [
    "# Acc met onbewerkte, ruwe review text als doc vector (spacy schoont en splitst)\n",
    "- SVM: 0.8218471636193155\n",
    "- KNN: 0.7740271917487107\n",
    "\n",
    "# Acc met tokenized en geschoonde tokens als doc vector \n",
    "- SVM: 0.8211439287388654\n",
    "- KNN: 0.7805907172995781\n",
    "\n",
    "# TODO\n",
    "- Uitproberen met individuele token vectors en niet de 'platgeslagen' doc vector.\n",
    "- Andere items uit de dataset als features toevoegen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4997655883731833"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier().fit(only_vec_train, only_label_train)\n",
    "knn_classifier.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return a.dot(b)/np.sqrt(a.dot(a) * b.dot(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def sklearn_model_evaluation(model, x_test, y_test):\n",
    "    # y_pred = model.predict(x_test)\n",
    "    # precision = precision_score(y_test, y_pred, average='micro')\n",
    "    # recall = recall_score(y_test, y_pred, average='micro')\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "\n",
    "    print(\"\\n##### Evaluation...\")\n",
    "    print(f\"  Accuracy: {accuracy}\") \n",
    "    print(f\"Precision: {precision}\\nRecall: {recall}\\nF-score: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-cc24e98a8505>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-cc24e98a8505>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(prec svm_classifier, only_we_train)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(prec svm_classifier, only_we_train)\n",
    "print(prec knn_classifier, only_we_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.8211439287388654\n",
      "Precision: 0.8211439287388654\n",
      "Recall: 0.8211439287388654\n",
      "F-score: \n",
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.7805907172995781\n",
      "Precision: 0.7805907172995781\n",
      "Recall: 0.7805907172995781\n",
      "F-score: \n"
     ]
    }
   ],
   "source": [
    "sklearn_model_evaluation(svm_classifier, only_vec_test, only_label_test)\n",
    "sklearn_model_evaluation(knn_classifier, only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuel token vectors als feature toevoegen\n",
    "extra punten uit dataset toevoegen, kijken of daar regression of correlation mee gedaan kan worden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2019-5'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "sorted([item['year_month'] for item in dataset if item['year_month'] != 'missing'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.540084388185654"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline.fit(only_vec_train, only_label_train)\n",
    "baseline.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-57d96f40e9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_vec_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "confusion_matrix(labels_test, svm_classifier.predict(only_vec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "from string import punctuation\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "from nltk import download, word_tokenize\n",
    "from nltk.classify import accuracy\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.metrics import precision, recall\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import (accuracy_score, confusion_matrix, f1_score,\n",
    "                             precision_score, recall_score)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def create_dataset(filepath, use_cache=False):\n",
    "    ''' Reads and cleans the csv file and structures the data '''\n",
    "\n",
    "    print('Reading in files...')\n",
    "\n",
    "    # Return early when a cache exists\n",
    "    if use_cache and os.path.isfile(CACHE_PATH):\n",
    "        with open(CACHE_PATH, 'rb') as cache:\n",
    "            print('Used cached dataset!')\n",
    "            return pickle.load(cache)\n",
    "\n",
    "    nlp = spacy.load('en_core_web_md', disable=['tagger', 'ner'])\n",
    "\n",
    "    dataset = []\n",
    "\n",
    "    # The translation and set are both a lot faster O(1) when compared to\n",
    "    # checking a list or string O(n).\n",
    "    punct_translation = str.maketrans('', '', punctuation)\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "\n",
    "    # ps = PorterStemmer()\n",
    "    lem = WordNetLemmatizer()\n",
    "\n",
    "    with open(filepath, 'r', encoding='latin-1') as f:\n",
    "        reader = csv.reader(f, delimiter=\",\", )\n",
    "\n",
    "        # Skip the header row\n",
    "        next(reader, None)\n",
    "\n",
    "        # Items per row:\n",
    "        #   0 -> review id\n",
    "        #   1 -> rating between 1-5\n",
    "        #   2 -> year and month\n",
    "        #   3 -> location of reviewer\n",
    "        #   4 -> review text\n",
    "        #   5 -> Disneyland location\n",
    "        for row in reader:\n",
    "            rating = int(row[1])\n",
    "\n",
    "            if rating < 3:\n",
    "                rating_label = 'negative'\n",
    "            elif rating == 3:\n",
    "                rating_label = 'indifferent'\n",
    "            else:\n",
    "                rating_label = 'positive'\n",
    "\n",
    "            # review_text = row[4] \\\n",
    "            #     .translate(punct_translation) \\\n",
    "            #     .lower() \\\n",
    "            #     .strip()\n",
    "\n",
    "            # tokenized = []\n",
    "            # for token in word_tokenize(review_text):\n",
    "            #     lemmatized = lem.lemmatize(token)\n",
    "            #     if lemmatized not in stoplist:\n",
    "            #         tokenized.append(lemmatized)\n",
    "\n",
    "            # tokenized = [\n",
    "                # Wordstemming -> SVM accuracy 0.815284 &  KNN accuracy 0.783638\n",
    "                # ps.stem(token) for token in word_tokenize(review_text)\n",
    "\n",
    "                # LEMMATIZATION -> SVM accuracy 0.810830 &  KNN accuracy 0.786217\n",
    "                #  for token in word_tokenize(review_text)\n",
    "\n",
    "                # token for token in word_tokenize(review_text)\n",
    "\n",
    "            #     if token not in stoplist\n",
    "            # ]\n",
    "\n",
    "            # bag_of_words = ({t: True for t in tokenized}, rating_label)\n",
    "\n",
    "            year, month = None, None\n",
    "            if row[2] != 'missing':\n",
    "                # 2019-4 for example\n",
    "                [year, month] = row[2].split('-')\n",
    "\n",
    "            dataset.append(\n",
    "                {\n",
    "                    # 'bag_of_words': bag_of_words,\n",
    "                    # 'review_text': row[4],\n",
    "                    # 'tokenized': tokenized,\n",
    "                    'rating_label': rating_label,\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'reviewer_location': row[3],\n",
    "                    'disneyland_location': row[5].replace('Disneyland_', ''),\n",
    "                    # 'doc_vector': nlp(' '.join(tokenized)).vector\n",
    "                }\n",
    "            )\n",
    "\n",
    "    with open('cache.pickle', 'wb') as p:\n",
    "        pickle.dump(dataset, p)\n",
    "\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Reading in files...\n",
      "  Training set: 34124\n",
      "  Test set: 4266\n",
      "  Development set: 4266\n"
     ]
    }
   ],
   "source": [
    "def split_train_test(feats, split=0.8):\n",
    "    ''' Creates test, train and dev splits from the dataset ''' \n",
    "    random.Random(1).shuffle(feats)\n",
    "\n",
    "    cutoff = int(len(feats) * split)\n",
    "    tenpercent = int((len(feats) - cutoff) / 2)\n",
    "    split = cutoff + tenpercent\n",
    "\n",
    "    train_feats = feats[:cutoff]\n",
    "    test_feats = feats[cutoff:split]\n",
    "    dev_feats = feats[split:]\n",
    "\n",
    "    print(\"  Training set: %i\" % len(train_feats))\n",
    "    print(\"  Test set: %i\" % len(test_feats))\n",
    "    print(\"  Development set: %i\" % len(dev_feats))\n",
    "\n",
    "    return train_feats, test_feats, dev_feats\n",
    "dataset = create_dataset('../data/DisneylandReviews.csv')\n",
    "\n",
    "train_feats, test_feats, dev_feats = split_train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_sklearn_model(model, test_examples, test_labels):\n",
    "    y_pred = model.predict(test_examples)\n",
    "    prec = precision_score(test_labels, y_pred, average='macro')\n",
    "    rec = recall_score(test_labels, y_pred, average='macro')\n",
    "    acc = accuracy_score(test_labels, y_pred)\n",
    "    f = f1_score(test_labels, y_pred, average='macro')\n",
    "\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {prec}\\nRecall: {rec}\\nF-score: {f}\")\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(test_labels, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewer_location_lookup = {}\n",
    "i = 1\n",
    "for item in dataset:\n",
    "    if item['reviewer_location'] in reviewer_location_lookup:\n",
    "        continue\n",
    "    reviewer_location_lookup[item['reviewer_location']] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "disney_loc_lookup = {}\n",
    "i = 1\n",
    "for item in dataset:\n",
    "    if item['disneyland_location'] in disney_loc_lookup:\n",
    "        continue\n",
    "    disney_loc_lookup[item['disneyland_location']] = i\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "-- BASELINE --\n",
      "\n",
      "Accuracy: 0.7887076537013802\n",
      "Precision: 0.2629025512337934\n",
      "Recall: 0.3333333333333333\n",
      "F-score: 0.2939580995136551\n",
      "Confusion matrix:\n",
      "[[   0    0  485]\n",
      " [   0    0  357]\n",
      " [   0    0 3143]]\n",
      "\n",
      "-- SVM --\n",
      "\n",
      "/home/wessel/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/wessel/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/home/wessel/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Accuracy: 0.7887076537013802\n",
      "Precision: 0.2629025512337934\n",
      "Recall: 0.3333333333333333\n",
      "F-score: 0.2939580995136551\n",
      "Confusion matrix:\n",
      "[[   0    0  485]\n",
      " [   0    0  357]\n",
      " [   0    0 3143]]\n",
      "\n",
      "-- KNN --\n",
      "\n",
      "Accuracy: 0.7503136762860728\n",
      "Precision: 0.379134523675315\n",
      "Recall: 0.34901820577150566\n",
      "F-score: 0.34219511435893374\n",
      "Confusion matrix:\n",
      "[[  25   18  442]\n",
      " [  19   21  317]\n",
      " [ 134   65 2944]]\n",
      "\n",
      "-- Decision Tree --\n",
      "\n",
      "Accuracy: 0.7535759096612296\n",
      "Precision: 0.37601503507225265\n",
      "Recall: 0.34690955435281823\n",
      "F-score: 0.3379377987481979\n",
      "Confusion matrix:\n",
      "[[  19   18  448]\n",
      " [  20   21  316]\n",
      " [ 121   59 2963]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "only_reviewer_country_train = [[\n",
    "    reviewer_location_lookup[i['reviewer_location']],\n",
    "    disney_loc_lookup[i['disneyland_location']],\n",
    "    int(i['year']),\n",
    "    int(i['month']),\n",
    "] for i in train_feats if i['year'] and i['month']]\n",
    "only_reviewer_label_train = [i['rating_label'] for i in train_feats if i['year'] and i['month']]\n",
    "\n",
    "only_reviewer_country_test = [[\n",
    "    reviewer_location_lookup[i['reviewer_location']],\n",
    "    disney_loc_lookup[i['disneyland_location']],\n",
    "    int(i['year']),\n",
    "    int(i['month']),\n",
    "] for i in test_feats if i['year'] and i['month']]\n",
    "only_reviewer_label_test = [i['rating_label'] for i in test_feats if i['year'] and i['month']]\n",
    "\n",
    "print('\\n-- BASELINE --\\n')\n",
    "baseline = DummyClassifier(strategy='most_frequent')\n",
    "baseline.fit(only_reviewer_country_train, only_reviewer_label_train)\n",
    "evaluation_sklearn_model(baseline, only_reviewer_country_test, only_reviewer_label_test)\n",
    "\n",
    "print('\\n-- SVM --\\n')\n",
    "svm = LinearSVC()\n",
    "svm.fit(only_reviewer_country_train, only_reviewer_label_train)\n",
    "evaluation_sklearn_model(svm, only_reviewer_country_test, only_reviewer_label_test)\n",
    "\n",
    "print('\\n-- KNN --\\n')\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(only_reviewer_country_train, only_reviewer_label_train)\n",
    "evaluation_sklearn_model(knn, only_reviewer_country_test, only_reviewer_label_test)\n",
    "\n",
    "print('\\n-- Decision Tree --\\n')\n",
    "dtc = DecisionTreeClassifier()\n",
    "dtc.fit(only_reviewer_country_train, only_reviewer_label_train)\n",
    "evaluation_sklearn_model(dtc, only_reviewer_country_test, only_reviewer_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}