{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38564bitmlpconda7f86b9b3c7f847e99c33aa47d858c0d9",
   "display_name": "Python 3.8.5 64-bit ('mlp': conda)",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk.classify\n",
    "from nltk.classify.scikitlearn import SklearnClassifier\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from collections import defaultdict\n",
    "from nltk.metrics import precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nTODO: word embeddings aan de dataset toevoegen\\nDenk dat bij het inlezen dit het beste is om te doen, dan hoeven we maar 1x door alles\\nheen te loopen. Even uitzoeken hoe de embedding vectors meegegeven moeten worden \\n(dict net als BOW of tuple met (<lijst met vectors>, <label>))\\n\\nEven experimenteren met wat beter werkt: \\n    - soort bow van individuele token vectors per review\\n    - of een gecombineerde methode gebruiken \\n        -> gemiddelde van alle token vectors\\n        -> doc vector\\n        -> ???\\n\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# We only need the sentence splitting and word embedding features, disabling the\n",
    "# unneed features makes this a lot faster.\n",
    "nlp = spacy.load('en_core_web_md', disable=['tagger', 'ner'])\n",
    "\n",
    "'''\n",
    "TODO: word embeddings aan de dataset toevoegen\n",
    "Denk dat bij het inlezen dit het beste is om te doen, dan hoeven we maar 1x door alles\n",
    "heen te loopen. Even uitzoeken hoe de embedding vectors meegegeven moeten worden \n",
    "(dict net als BOW of tuple met (<lijst met vectors>, <label>))\n",
    "\n",
    "Even experimenteren met wat beter werkt: \n",
    "    - soort bow van individuele token vectors per review\n",
    "    - of een gecombineerde methode gebruiken \n",
    "        -> gemiddelde van alle token vectors\n",
    "        -> doc vector\n",
    "        -> ???\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/wessel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "  Training set: 34124\n",
      "  Test set: 4266\n",
      "  Development set: 4266\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import random\n",
    "import sys\n",
    "from string import punctuation\n",
    "import pickle\n",
    "\n",
    "from nltk import download, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download the nltk stopwords corpus if needed\n",
    "download('stopwords')\n",
    "\n",
    "\n",
    "def create_dataset(filepath):\n",
    "    ''' Reads and cleans the csv file and structures the datapoints ''' \n",
    "    dataset = []\n",
    "\n",
    "    # The translation and set are both a lot faster O(1) \n",
    "    # when compared to checking a list or string O(n).\n",
    "    punct_translation = str.maketrans('', '', punctuation)\n",
    "    stoplist = set(stopwords.words('english'))\n",
    "\n",
    "    with open(filepath, 'r', encoding='latin-1') as f:\n",
    "        reader = csv.reader(f, delimiter=\",\", )\n",
    "        \n",
    "        # Skip the header row\n",
    "        next(reader, None)\n",
    "\n",
    "        # Items per row:\n",
    "        #   0 -> review id\n",
    "        #   1 -> rating between 1-5\n",
    "        #   2 -> year and month\n",
    "        #   3 -> location of reviewer\n",
    "        #   4 -> review text\n",
    "        #   5 -> Disneyland location\n",
    "        for row in reader:\n",
    "            rating = int(row[1])\n",
    "\n",
    "            if rating < 3:\n",
    "                rating_label = 'negative'\n",
    "            elif rating == 3:\n",
    "                rating_label = 'indifferent'\n",
    "            else:\n",
    "                rating_label = 'positive'\n",
    "\n",
    "            review_text = row[4] \\\n",
    "                .translate(punct_translation) \\\n",
    "                .lower() \\\n",
    "                .strip() + f\"{row[5].replace('Disneyland_', '')} {row[3]}\"\n",
    "\n",
    "            tokenized = [\n",
    "                token for token in word_tokenize(review_text)\n",
    "                if token not in stoplist\n",
    "            ]\n",
    "\n",
    "            bag_of_words = ({t: True for t in tokenized}, rating)\n",
    "\n",
    "            dataset.append(\n",
    "                {\n",
    "                    'tokenized': tokenized, \n",
    "                    'bag_of_words': bag_of_words, \n",
    "                    'rating_label': rating, \n",
    "                    'year_month': row[2], \n",
    "                    'reviewer_location': row[3], \n",
    "                    'review_text': row[4], \n",
    "                    'disneyland_location': row[5],\n",
    "                    'doc_vector': nlp(' '.join(tokenized)).vector\n",
    "                }\n",
    "            )\n",
    "\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def split_train_test(feats, split=0.8):\n",
    "    ''' Creates test, train and dev splits from the dataset ''' \n",
    "    random.Random(1).shuffle(feats)\n",
    "\n",
    "    cutoff = int(len(feats) * split)\n",
    "    tenpercent = int((len(feats) - cutoff) / 2)\n",
    "    split = cutoff + tenpercent\n",
    "\n",
    "    train_feats = feats[:cutoff]\n",
    "    test_feats = feats[cutoff:split]\n",
    "    dev_feats = feats[split:]\n",
    "\n",
    "    print(\"  Training set: %i\" % len(train_feats))\n",
    "    print(\"  Test set: %i\" % len(test_feats))\n",
    "    print(\"  Development set: %i\" % len(dev_feats))\n",
    "\n",
    "    return train_feats, test_feats, dev_feats\n",
    "dataset = create_dataset('../data/DisneylandReviews.csv')\n",
    "\n",
    "train_feats, test_feats, dev_feats = split_train_test(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_recall(classifier, testfeats):\n",
    "\trefsets = defaultdict(set)\n",
    "\ttestsets = defaultdict(set)\n",
    "\t\n",
    "\tfor i, (feats, label) in enumerate(testfeats):\n",
    "\t\trefsets[label].add(i)\n",
    "\t\tobserved = classifier.classify(feats)\n",
    "\t\ttestsets[observed].add(i)\n",
    "\t\n",
    "\tprecisions = {}\n",
    "\trecalls = {}\n",
    "\t\n",
    "\tfor label in classifier.labels():\n",
    "\t\tprecisions[label] = precision(refsets[label], testsets[label])\n",
    "\t\trecalls[label] = recall(refsets[label], testsets[label])\n",
    "\t\n",
    "\treturn precisions, recalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_f(precisions, recalls):\n",
    "    f_measures = {}\n",
    "\n",
    "    for category in precisions.keys():\n",
    "        # This is done to prevent the program from crashing when \n",
    "        # no measure is provided for a particular category\n",
    "        if not precisions[category] or not recalls[category]:\n",
    "            f_measures[category] = None\n",
    "            continue\n",
    "\n",
    "        f_measures[category] = round(\n",
    "            2 * ((precisions[category] * recalls[category]) /\n",
    "                 (precisions[category] + recalls[category])), 6)\n",
    "\n",
    "    return f_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(classifier, test_feats, categories):\n",
    "    \"\"\" Taken from assignment 1, calculates and prints evaluation measures \"\"\"\n",
    "    print(\"\\n##### Evaluation...\")\n",
    "    print(\"  Accuracy: %f\" % nltk.classify.accuracy(classifier, test_feats))\n",
    "    precisions, recalls = precision_recall(classifier, test_feats)\n",
    "    f_measures = calculate_f(precisions, recalls)\n",
    "\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")\n",
    "    print(\" |%-11s|%-11s|%-11s|%-11s|\" %\n",
    "          (\"category\", \"precision\", \"recall\", \"F-measure\"))\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")\n",
    "    for category in categories:\n",
    "        if precisions[category] is None:\n",
    "            print(\" |%-11s|%-11s|%-11s|%-11s|\" % (category, \"NA\", \"NA\", \"NA\"))\n",
    "        else:\n",
    "            print(\" |%-11s|%-11f|%-11f|%-11s|\" %\n",
    "                  (category,\n",
    "                   precisions[category],\n",
    "                   recalls[category],\n",
    "                   f_measures[category])\n",
    "                  )\n",
    "    print(\" |-----------|-----------|-----------|-----------|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svm(train_feats):\n",
    "    ''' Trains and returns a linear SVM classifier '''\n",
    "    return SklearnClassifier(LinearSVC(dual=False)).train(train_feats)\n",
    "\n",
    "def train_knn(train_feats):\n",
    "    ''' Trains and returns a KNN classifier '''\n",
    "    return SklearnClassifier(KNeighborsClassifier()).train(train_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_bow_test = [item['bag_of_words'] for item in test_feats]\n",
    "only_bow_train = [item['bag_of_words'] for item in train_feats]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = train_svm(only_bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_classifier = train_knn(only_bow_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(svm_classifier, only_bow_test, ['positive', 'indifferent', 'negative'])\n",
    "evaluation(knn_classifier, only_bow_test, ['positive', 'indifferent', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_we_test = [(item['doc_vector'], item['rating_label']) for item in test_feats]\n",
    "only_we_train = [(item['doc_vector'], item['rating_label']) for item in train_feats]\n",
    "\n",
    "only_vec_train = [i[0] for i in only_we_train]\n",
    "only_label_train = [j[1] for j in only_we_train]\n",
    "\n",
    "only_vec_test = [i[0] for i in only_we_test]\n",
    "only_label_test = [j[1] for j in only_we_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_classifier = LinearSVC().fit(only_vec_train, only_label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5977496483825597"
      ]
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "svm_classifier.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.43694327238631037"
      ]
     },
     "metadata": {},
     "execution_count": 154
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "a = DecisionTreeClassifier().fit(only_vec_train, only_label_train)\n",
    "a.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "countries = {i['reviewer_location'] for i in dataset}\n",
    "disneylands = {i['disneyland_location'].replace('Disneyland_', '') for i in dataset}\n",
    "\n",
    "disneyland_lookup = { disneyland: nlp(disneyland).vector for disneyland in disneylands }\n",
    "country_lookup = { country: nlp(country).vector for country in countries }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_features_train = []\n",
    "labels_train = []\n",
    "\n",
    "for row in train_feats:\n",
    "    # We know these are always present in de dataset\n",
    "    features = row['doc_vector']\n",
    "\n",
    "    # if row['year_month'] == 'missing':\n",
    "    #     features = np.concatenate((features, np.array([0, 0])))\n",
    "    # else:\n",
    "    #     # example format: 2019-4\n",
    "    #     year, month = row['year_month'].split('-')\n",
    "    #     features = np.concatenate((features, np.array([int(year), int(month)])))\n",
    "    features = np.append(\n",
    "        features, \n",
    "        disneyland_lookup[row['disneyland_location'].replace('Disneyland_', '')]\n",
    "    )\n",
    "    features = np.append(features, country_lookup[row['reviewer_location']])\n",
    "\n",
    "    combined_features_train.append(features)\n",
    "    labels_train.append(row['rating_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_features_test = []\n",
    "labels_test = []\n",
    "for row in test_feats:\n",
    "    # We know these are always present in de dataset\n",
    "    features = row['doc_vector']\n",
    "    # features = np.array([])\n",
    "\n",
    "    # The feature arrays need to have the same shape, that is why we\n",
    "    # insert 0s in here\n",
    "    # if row['year_month'] == 'missing':\n",
    "    #     features = np.concatenate((features, np.array([0, 0])))\n",
    "    # else:\n",
    "    #     # example format: 2019-4\n",
    "    #     year, month = row['year_month'].split('-')\n",
    "    #     features = np.concatenate((features, np.array([int(year), int(month)])))\n",
    "\n",
    "    features = np.append(\n",
    "        features, \n",
    "        disneyland_lookup[row['disneyland_location'].replace('Disneyland_', '')]\n",
    "    )\n",
    "    features = np.append(features, country_lookup[row['reviewer_location']])\n",
    "\n",
    "    combined_features_test.append(features)\n",
    "    labels_test.append(row['rating_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/home/wessel/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/svm/_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5925925925925926"
      ]
     },
     "metadata": {},
     "execution_count": 178
    }
   ],
   "source": [
    "svm_extra_features = LinearSVC().fit(combined_features_train, labels_train)\n",
    "svm_extra_features.score(combined_features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'tokenized': ['convenience', 'staffs', 'friendly', 'many', 'rude', 'mainland', 'ppl', 'didnt', 'need', 'line', 'long', 'time', 'rides', 'several', 'restaurants', 'provide', 'nice', 'food'], 'bag_of_words': ({'convenience': True, 'staffs': True, 'friendly': True, 'many': True, 'rude': True, 'mainland': True, 'ppl': True, 'didnt': True, 'need': True, 'line': True, 'long': True, 'time': True, 'rides': True, 'several': True, 'restaurants': True, 'provide': True, 'nice': True, 'food': True}, 'positive'), 'rating_label': 'positive', 'year_month': '2016-12', 'reviewer_location': 'Hong Kong', 'review_text': 'Convenience, Staffs are friendly ,, there are not many rude mainland ppl,, didnt need to line up for long time for rides,   There are several restaurants provide nice food.', 'disneyland_location': 'Disneyland_HongKong', 'doc_vector': array([ 8.26215744e-03,  2.48817932e-02, -1.40969366e-01, -2.98998266e-01,\n        2.03529805e-01,  1.41831204e-01,  7.97833502e-02, -1.58968836e-01,\n        1.25683704e-02,  2.18018961e+00, -2.16656134e-01, -8.32059383e-02,\n        1.95899755e-02,  1.94423683e-02, -1.78535521e-01, -1.26981720e-01,\n       -1.10207908e-01,  1.11973250e+00, -9.99247432e-02, -3.02733183e-02,\n       -1.42959803e-01,  1.34889573e-01,  7.68425595e-03, -1.02654360e-01,\n        1.28734693e-01,  1.80763155e-02, -1.08306743e-01, -1.56741455e-01,\n        1.16818927e-01, -5.19425273e-02, -7.11692788e-04, -7.90104270e-02,\n       -4.57759462e-02, -1.17571615e-01,  7.39459842e-02, -1.11605301e-02,\n        1.11644618e-01,  2.37194747e-02, -1.27143428e-01,  8.67502689e-02,\n       -1.47649884e-01, -4.27900404e-02, -1.70620997e-02, -5.28801568e-02,\n        7.74667040e-02,  1.39552042e-01,  3.50495726e-02,  4.67126295e-02,\n        4.20314744e-02, -5.09617254e-02, -1.95529923e-01, -2.12064795e-02,\n        1.61097273e-01,  5.58712110e-02, -6.36019185e-02,  4.47471067e-02,\n       -1.69115886e-02, -8.06639120e-02,  3.38222571e-02,  2.08934434e-02,\n        1.23236403e-01, -2.02231228e-01, -1.25768214e-01,  1.37312874e-01,\n        8.54615271e-02, -2.08847281e-02,  3.87589037e-02,  2.58006334e-01,\n        1.29822806e-01,  2.21750513e-01,  1.43144011e-01,  1.67118847e-01,\n        1.10646628e-01,  2.23222133e-02,  2.22927123e-01,  7.74317756e-02,\n        1.01187147e-01,  5.18972985e-03,  4.05575102e-03,  2.11656138e-01,\n        1.86800584e-01, -4.38520014e-02, -1.01508453e-01, -6.84934780e-02,\n       -1.02343373e-01,  1.44823631e-02,  2.45318301e-02,  2.33556852e-01,\n        7.69519508e-02, -1.42846346e-01, -2.09094167e-01, -5.05993180e-02,\n       -1.17459372e-01, -1.89148914e-02,  1.69559941e-01, -1.19869001e-02,\n        1.83395259e-02, -1.43174320e-01,  7.66581595e-02,  6.63983822e-03,\n       -1.06211685e-01, -3.25126871e-02, -9.63822827e-02,  1.88524853e-02,\n        1.36511475e-01, -9.45913613e-01,  2.44002849e-01, -1.08653158e-01,\n       -6.75301179e-02, -6.89683408e-02,  7.55363107e-02, -3.42128724e-01,\n        6.40835240e-02,  1.37536481e-01,  2.00433675e-02, -1.29313022e-01,\n        2.32191049e-02, -1.55064002e-01, -2.13061452e-01,  3.28671038e-02,\n        1.17508195e-01, -8.98917299e-03,  1.72541887e-02, -1.52599826e-01,\n        2.73247901e-02, -1.49410546e-01,  1.31402537e-01, -2.38225237e-01,\n       -4.68078861e-03,  1.42135257e-02,  2.98700649e-02, -2.38751322e-02,\n       -5.06161265e-02, -4.65724654e-02, -4.12878171e-02, -1.95586830e-02,\n        4.66971099e-02, -6.24134801e-02,  6.30398393e-02, -1.86756831e-02,\n       -1.28571010e+00,  2.47872826e-02,  2.24331632e-01, -2.76853479e-02,\n        5.97955883e-02, -1.37148321e-01, -2.82873213e-01, -6.71143585e-04,\n       -1.87792983e-02, -5.55611476e-02, -1.46286879e-02,  2.05371469e-01,\n        8.92329067e-02, -1.34035572e-01,  4.37866263e-02,  8.92818347e-02,\n        1.07369974e-01, -2.79765874e-02,  1.39420822e-01, -9.13354754e-02,\n       -4.72346917e-02, -7.34069943e-03, -1.21790655e-02, -8.77090991e-02,\n        1.40749574e-01, -2.08558477e-02, -6.47054380e-03, -1.04228295e-01,\n       -1.70581753e-03, -1.03223100e-01,  6.07119985e-02,  5.28025515e-02,\n       -1.07215367e-01, -6.53244331e-02, -1.19085766e-01,  1.13791995e-01,\n       -8.38763565e-02,  1.22384369e-01, -2.39546667e-03,  7.26582035e-02,\n        1.22944884e-01, -1.41424879e-01, -2.38030136e-01,  5.91351166e-02,\n       -4.09522131e-02, -1.53558865e-01,  2.37387363e-02, -1.19746722e-01,\n        1.65081918e-01, -6.45724982e-02,  8.87298137e-02,  4.01342735e-02,\n       -9.30148140e-02, -5.30327000e-02, -7.56975859e-02,  1.21995257e-02,\n        7.08432272e-02, -5.22687696e-02,  7.64466822e-02,  1.17134586e-01,\n        1.10529521e-02, -1.03904745e-02, -5.53188063e-02, -8.94667506e-02,\n        2.74927139e-01,  1.49875492e-01,  4.05438952e-02,  2.07698494e-02,\n        8.82385373e-02,  8.23304243e-03, -3.34982164e-02, -4.69542146e-02,\n       -5.83561957e-02, -9.34786871e-02,  1.28664240e-01,  5.45747355e-02,\n        8.16462040e-02, -6.60035089e-02, -8.12363327e-02,  1.01004712e-01,\n        2.49574762e-02, -5.00166304e-02,  9.78486016e-02,  6.09328821e-02,\n        1.78782865e-02,  6.96507022e-02, -1.04041047e-01,  3.03445514e-02,\n       -1.05933130e-01, -5.01695508e-03, -5.36666922e-02, -8.13689977e-02,\n        1.48745164e-01,  4.60314751e-02,  2.68616915e-01, -3.50449933e-03,\n        5.57508841e-02, -1.43884435e-01, -1.05399072e-01,  2.15386540e-01,\n        4.91852826e-03,  2.24905722e-02, -7.25756660e-02,  1.63250282e-01,\n        7.31617585e-02,  3.05028912e-02, -2.82160401e-01, -1.18107520e-01,\n       -2.47485057e-01,  7.85601065e-02, -5.24530187e-03,  6.00137049e-03,\n       -1.29831269e-01,  6.88859448e-02, -2.72314792e-04,  3.57747644e-01,\n        2.37496849e-02, -9.12114084e-02, -1.87548921e-01,  5.75150624e-02,\n       -4.44940589e-02,  1.22924857e-01, -7.24252611e-02,  1.58846341e-02,\n       -7.37315193e-02, -3.13232020e-02,  4.48035225e-02,  1.62082538e-01,\n        1.90345585e-01,  1.23479001e-01, -2.36664146e-01,  2.65111085e-02,\n       -2.22311765e-02, -1.89289287e-01, -2.94562075e-02,  2.14343041e-01,\n        4.50727418e-02,  3.59030515e-02,  1.08802997e-01,  1.73218623e-01,\n       -8.44274182e-03,  1.37012839e-01,  4.14466821e-02,  2.59949118e-01,\n       -7.83860981e-02, -1.54447826e-02,  1.96974695e-01, -2.02616267e-02,\n        7.32047632e-02,  1.16019376e-01, -1.12544678e-01,  3.76474555e-03,\n       -8.93949419e-02, -6.03180490e-02,  9.86498520e-02,  4.26245853e-02,\n        1.07392915e-01, -1.16848066e-01,  1.54537842e-01,  2.17653751e-01],\n      dtype=float32)}\n[ 2 28]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array(['positive'], dtype='<U11')"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "ex = dev_feats[9]\n",
    "\n",
    "print(ex)\n",
    "\n",
    "f = np.array([disneyland_lookup[ex['disneyland_location']], country_lookup[ex['reviewer_location']]])\n",
    "\n",
    "print(f)\n",
    "\n",
    "svm_extra_features.predict(f.reshape(1,-1))"
   ]
  },
  {
   "source": [
    "# Acc met onbewerkte, ruwe review text als doc vector (spacy schoont en splitst)\n",
    "- SVM: 0.8218471636193155\n",
    "- KNN: 0.7740271917487107\n",
    "\n",
    "# Acc met tokenized en geschoonde tokens als doc vector \n",
    "- SVM: 0.8211439287388654\n",
    "- KNN: 0.7805907172995781\n",
    "\n",
    "# TODO\n",
    "- Uitproberen met individuele token vectors en niet de 'platgeslagen' doc vector.\n",
    "- Andere items uit de dataset als features toevoegen."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4997655883731833"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ],
   "source": [
    "knn_classifier = KNeighborsClassifier().fit(only_vec_train, only_label_train)\n",
    "knn_classifier.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(a, b):\n",
    "    return a.dot(b)/np.sqrt(a.dot(a) * b.dot(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "def sklearn_model_evaluation(model, x_test, y_test):\n",
    "    # y_pred = model.predict(x_test)\n",
    "    # precision = precision_score(y_test, y_pred, average='micro')\n",
    "    # recall = recall_score(y_test, y_pred, average='micro')\n",
    "    accuracy = model.score(x_test, y_test)\n",
    "\n",
    "    print(\"\\n##### Evaluation...\")\n",
    "    print(f\"  Accuracy: {accuracy}\") \n",
    "    print(f\"Precision: {precision}\\nRecall: {recall}\\nF-score: \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-18-cc24e98a8505>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-18-cc24e98a8505>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    print(prec svm_classifier, only_we_train)\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "print(prec svm_classifier, only_we_train)\n",
    "print(prec knn_classifier, only_we_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.8211439287388654\n",
      "Precision: 0.8211439287388654\n",
      "Recall: 0.8211439287388654\n",
      "F-score: \n",
      "\n",
      "##### Evaluation...\n",
      "  Accuracy: 0.7805907172995781\n",
      "Precision: 0.7805907172995781\n",
      "Recall: 0.7805907172995781\n",
      "F-score: \n"
     ]
    }
   ],
   "source": [
    "sklearn_model_evaluation(svm_classifier, only_vec_test, only_label_test)\n",
    "sklearn_model_evaluation(knn_classifier, only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individuel token vectors als feature toevoegen\n",
    "extra punten uit dataset toevoegen, kijken of daar regression of correlation mee gedaan kan worden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'2019-5'"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "sorted([item['year_month'] for item in dataset if item['year_month'] != 'missing'])[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.540084388185654"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "baseline = DummyClassifier(strategy=\"most_frequent\")\n",
    "baseline.fit(only_vec_train, only_label_train)\n",
    "baseline.score(only_vec_test, only_label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Mix of label input types (string and number)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-57d96f40e9f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msvm_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monly_vec_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                           FutureWarning)\n\u001b[1;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 281\u001b[0;31m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munique_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    282\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/mlp/lib/python3.8/site-packages/sklearn/utils/multiclass.py\u001b[0m in \u001b[0;36munique_labels\u001b[0;34m(*ys)\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m# Check that we don't mix string type with number type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mix of label input types (string and number)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Mix of label input types (string and number)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "confusion_matrix(labels_test, svm_classifier.predict(only_vec_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}